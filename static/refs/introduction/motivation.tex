% - The raise of Large Language Model recently
% - Howerver, the problem of factuality that Large Language Model providing
% - Some previous work addressed this issues, like fine-tuning Large Language Model in specific domains, but it is costly. Another approach is retrieval augmented generation, by constructing knowledge base as vector database stored latent representation of each knowledge, then retrieved only neccessary and feed generators to generate text. This way is effective to address this issue without costing like above method. However, in some cases, this can be perform worst than generator, which is proved in the experiments section
% - Based on these limitation, this project will take advantages from previous works and develop new proposal to handle the remain problem from previous approach
\section{Motivation}
The advent of Large Language Models has revolutionized the field of natural language processing (NLP). These models, such as Llama-2, GPT-4, ... have demonstrated unprecedented capabilities in understanding and generating human-like text, opening up new possibilities for applications ranging from chatbots to content generation.\\\\
However, a significant challenge that these models face is ensuring the factuality of the information they provide. Due to their training on vast amounts of data, these models can sometimes generate outputs that are plausible-sounding but factually incorrect. This issue poses a significant hurdle for the deployment of these models in applications where accuracy and reliability of information are paramount.\\\\
Previous works have attempted to address this issue in various ways. One approach is to fine-tune Large Language Models in specific domains. While this method can improve the model's performance in the targeted domain, it is costly in terms of computational resources and requires substantial amounts of domain-specific training data.\\\\
Another approach is retrieval-augmented generation. This process involves building a knowledge base in the form of a vector database, which holds the latent representation of each piece of information. The Large Language Model, acting as the generator, then selectively retrieves the required information from this database. This information is then used to generate text. This strategy efficiently tackles the issue of factuality without incurring the high computational costs associated with the fine-tuning approach.\\\\
Nonetheless, retrieval-augmented generation is not without its limitations. In some cases, this method can perform worse than a standalone generator. This performance discrepancy underscores the need for further research and development in this area.\\\\
Given these limitations, the project aims to build upon the strengths of previous works while developing new proposal to handle the problems. By leveraging the advancements in Large Language Models and retrieval-augmented generation, the project seeks to devise a more effective solution to the factuality issue in Large Language Models.
