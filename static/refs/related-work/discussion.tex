\section{Discussion}
In this chapter, we have seen three distinct approaches to enhance the capabilities of Large Language Models. The first approach, fine-tuning Large Language Models, adapts a pre-trained model to a specific domain or task. This method can improve the model's performance in the targeted domain or task and leverage the general knowledge of the pre-trained language model. However, it can be costly in terms of computational resources and data requirements, and may lead to catastrophic forgetting or poor generalization to out-of-domain scenarios.\\\\
The second approach, retrieval-augmented generation, combines a pre-trained language model with a dense retriever that selects relevant information from a large corpus. This method can address the factuality issue of the Large Language Models, efficiently access and integrate external knowledge sources without fine-tuning. However, retrieval-augmented generation may have difficulty exploring a vast range of documents, especially if they are diverse, noisy, or outdated. Retrieval-augmented generation may also miss important information that is not explicitly stated in the documents.\\\\
The third approach, graph reasoning leverages knowledge graphs to enhance the reasoning capabilities of pretrained language models. While knowledge graphs offer rich semantic information through structured representations of entities and relations, effectively integrating this information poses significant challenges. These challenges include identifying relevant knowledge within large knowledge graphs, performing joint reasoning over both natural language and graph inputs, and inferring implicit knowledge not explicitly stated in the graph.\\\\
Inspired by the strengths and limitations of existing approaches, this project aims to develop a method that efficiently and accurately augments the knowledge of a Large Language Model. We recognize the potential of knowledge graph embedding to address these challenges. Knowledge graph embedding compactly represents entities and relations as vectors, capturing their semantic relationships and enabling efficient knowledge integration within the LLM framework. This approach allows us to leverage the rich information contained in knowledge graphs while mitigating the challenges of missing or implicit knowledge that hinder other methods.