\chapter{Related works}
% \hline
\indent\textit{Large language models have emerged as a powerful tool for a variety of tasks. These models, trained on vast amounts of data, have demonstrated remarkable capabilities in understanding and generating human-like text \cite{NEURIPS2020_1457c0d6}. However, despite their impressive performance, these models are not without their limitations. The need to enhance their knowledge base and improve their efficiency and accuracy is a pressing concern. In this context, Chapter 3 delves into several related works that explore different approaches to address these challenges. The chapter provides a comprehensive overview of these methods, highlighting their strengths and weaknesses, and sets the stage for our proposed solution. }


\input{related-work/finetuning}
\input{related-work/rag}
\input{related-work/graph_reasoning}
\input{related-work/discussion}

% \input{technologies/front-end-dev}
% \input{technologies/back-end-dev}
% \input{technologies/database-management-system}
% \input{technologies/recommendation-system}