\section{Fine-tuning Large Language Model}
Several recent works have explored the potential of fine-tuning for adapting large language models (LLM) to specific domains and tasks.\\\\
A research about adapting language models to domains and tasks \cite{gururangan-etal-2020-dont} investigates whether it is beneficial to tailor a pretrained language model to the domain of a target task, by continuing to pretrain on domain-specific and task-specific data. The paper presents a study across four domains (biomedical and computer science publications, news, and reviews) and eight classification tasks, showing that a second phase of pretraining in-domain (domain-adaptive pretraining) leads to performance gains, under both high- and low-resource settings.\\\\
Fine-tuning is a common technique to adapt large language models to specific tasks or domains. However, fine-tuning has a drawback about high computational and storage costs. To address these issues, parameter-efficient fine-tuning (PEFT) methods \cite{conf/icml/HoulsbyGJMLGAG19, ben-zaken-etal-2022-bitfit, li-liang-2021-prefix, hu2022lora} have been proposed, which only fine-tune a small subset of parameters while freezing the rest of the LLM. PEFT methods can reduce the resource requirements, preserve the knowledge of the LLM, and improve the robustness of the model.
